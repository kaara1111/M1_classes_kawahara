{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"id":"l1SW3KQ8SzSx"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import random\n","import math\n","import csv\n","\n","# def PW_mechanism(t, epsilon):\n","#   if t<-1.0:\n","#     t=-1.0\n","#   elif t>1.0:\n","#     t=1.0\n","#   else:\n","#     pass\n","#   # print(\"t:\", t)\n","#   C = (((math.e)**(epsilon/2)+1)/((math.e)**(epsilon/2)-1))\n","#   # p = ((math.e)**epsilon-(math.e)**(epsilon/2))/(2*math.e**(epsilon/2)+2)\n","#   l = (C+1)*t/2-(C-1)/2\n","#   r = l+C-1\n","#   x = random.uniform(0, 1)\n","#   if x < (math.e)**(epsilon/2)/((math.e)**(epsilon/2)+1):\n","#     return random.uniform(l,r)\n","#   else:\n","#     choice_prob = [(t+1)/2, (-t+1)/2]\n","#     chosen_area = np.random.choice([0,1], p=choice_prob)\n","#     if chosen_area==0:\n","#       return random.uniform(-C, l)\n","#     else:\n","#       return random.uniform(r, C)\n","\n","# def multiple_PW(t, epsilon):\n","#   C = (((math.e)**(epsilon/2)+1)/((math.e)**(epsilon/2)-1))\n","#   d = len(t)\n","#   ret = [0 for i in range(d)]\n","#   k = max(1, min(d, int(epsilon/2.5)))\n","#   tmp_lst = [i for i in range(d)]\n","#   idx_lst = np.random.choice(tmp_lst, k, replace=False)\n","#   # print(idx_lst)\n","  \n","#   for j in tmp_lst:\n","#     if j in idx_lst:\n","#       x = PW_mechanism(t[j],epsilon/k)\n","#       ret[j] = d*x/k\n","#     else:\n","#       ret[j] = random.uniform(-C,C)\n","  \n","#   # for j in idx_lst:\n","#   #   x = PW_mechanism(t[j],epsilon/k)\n","#   #   ret[j] = d*x/k\n","\n","#   return ret\n","\n","# def noising_purpose_variable(label, epsilon):\n","#   prob0 = [math.e**epsilon/(1+math.e**epsilon), 1/(1+math.e**epsilon)]\n","#   prob1 = [1/(1+math.e**epsilon), math.e**epsilon/(1+math.e**epsilon)]\n","#   if label==0.0:\n","#     label = np.random.choice([0,1], p=prob0)\n","#   else:\n","#     label = np.random.choice([0,1], p=prob1)\n","  \n","#   return label\n","\n","# cnt = 0\n","# for i in range(1000):\n","#   if noising_purpose_variable(0.0, 1.0)==0.0:\n","#     cnt+=1\n","# print(cnt)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dylxlmPGUHvK"},"outputs":[],"source":["# def multiple_PW_columns_k(t, epsilon, k):\n","#   d = len(t)\n","#   ret = [0 for i in range(d)]\n","#   tmp_lst = [i for i in range(d)]\n","#   idx_lst = np.random.choice(tmp_lst, k, replace=False)\n","#   # print(idx_lst)\n","  \n","#   for j in idx_lst:\n","#     x = PW_mechanism(t[j],epsilon/k)\n","#     ret[j] = d*x/k\n","  \n","#   return ret"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":54052,"status":"ok","timestamp":1657071193288,"user":{"displayName":"川原尚己","userId":"01349954751757802546"},"user_tz":-540},"id":"XuNACNugOxY9","outputId":"658c5133-3bf7-4844-de0f-c3fe0f539a48"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\laplacian\\AppData\\Local\\Temp\\ipykernel_63148\\3885700970.py:88: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data.iloc[:,0] = data.iloc[:,0].astype('int')\n"]},{"name":"stdout","output_type":"stream","text":["closed_test_score: 0.9806678383128296\n","open_text_score: 0.9719298245614035\n","cross_test_score: 0.9771929824561404\n"]},{"ename":"ValueError","evalue":"The number of classes has to be greater than one; got 1 class","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_63148\\3885700970.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    169\u001b[0m   \u001b[1;31m# # plt.legend()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_63148\\3885700970.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    111\u001b[0m       \u001b[0msplit_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_split_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcopy_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m       \u001b[0mctest_scores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_closed_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m       \u001b[0motest_scores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_open_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m       \u001b[0mcross_scores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_cross_validation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msplit_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msplit_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data_num:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_63148\\3885700970.py\u001b[0m in \u001b[0;36mlearning_open_test\u001b[1;34m(train_data, test_data, clf)\u001b[0m\n\u001b[0;32m     23\u001b[0m   \u001b[1;31m# clf = svm.SVC(gamma=0.5, C=1., kernel='rbf')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m   \u001b[1;31m# clf = svm.SVC(kernel='rbf', random_state=None)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m   \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m   \u001b[1;31m# # 学習結果を出力\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\laplacian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    197\u001b[0m             )\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m         sample_weight = np.asarray(\n","\u001b[1;32mc:\\Users\\laplacian\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_validate_targets\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    718\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_weight_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_class_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 720\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    721\u001b[0m                 \u001b[1;34m\"The number of classes has to be greater than one; got %d class\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    722\u001b[0m                 \u001b[1;33m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mValueError\u001b[0m: The number of classes has to be greater than one; got 1 class"]}],"source":["from sklearn import svm\n","from sklearn.datasets import load_iris\n","import joblib\n","import matplotlib.pyplot as plt\n","from sklearn import metrics\n","from sklearn.model_selection import cross_val_score, KFold\n","from scipy.stats import sem\n","import pandas as pd\n","import numpy as np\n","import random\n","import math\n","import csv\n","import sys\n","import copy\n","\n","def learning_open_test(train_data, test_data, clf):\n","  # 説明変数：\n","  train_X = train_data.iloc[:, 1:].values\n","  # 目的変数：\n","  train_y = train_data.iloc[:,0].values\n","\n","  # 学習（SVM）\n","  # clf = svm.SVC(gamma=0.5, C=1., kernel='rbf')\n","  # clf = svm.SVC(kernel='rbf', random_state=None)\n","  clf.fit(train_X, train_y)\n","  # # 学習結果を出力\n","\n","  # 説明変数:\n","  test_X = test_data.iloc[:, 1:].values\n","  # 目的変数：\n","  test_y = test_data.iloc[:,0].values\n","\n","  # 学習結果の検証（テスト用データx1, x2を入力）\n","  predicted_y = clf.predict(test_X)\n","  # 正解データと予測データを比較し、スコアを計算\n","  score = metrics.accuracy_score(test_y, predicted_y)\n","\n","\n","  # print(\"Score:\", score)\n","  return score\n","\n","def learning_closed_test(train_data, clf):\n","  # 説明変数：\n","  train_X = train_data.iloc[:, 1:].values\n","  # 目的変数：\n","  train_y = train_data.iloc[:,0].values\n","\n","  # 学習（SVM）\n","  # clf = svm.SVC(gamma=0.5, C=1., kernel='rbf')\n","  # clf = svm.SVC(kernel='rbf', random_state=None)\n","  clf.fit(train_X, train_y)\n","  # # 学習結果を出力\n","\n","  # 説明変数:\n","  test_X = train_data.iloc[:, 1:].values\n","  # 目的変数：\n","  test_y = train_data.iloc[:,0].values\n","\n","  # 学習結果の検証（テスト用データx1, x2を入力）\n","  predicted_y = clf.predict(test_X)\n","  # 正解データと予測データを比較し、スコアを計算\n","  score = metrics.accuracy_score(test_y, predicted_y)\n","\n","\n","  # print(\"Score:\", score)\n","  return score\n","\n","def evaluate_cross_validation(clf, x, y, K):\n","  cv = KFold(K, shuffle=True,random_state=0)\n","  scores = cross_val_score(clf,x,y,cv=cv)\n","  # print(scores)\n","  # print (\"Mean score: {} (+/-{})\".format( np.mean (scores), sem(scores)))\n","\n","  return np.mean(scores)\n","\n","def get_split_data(data, num):\n","  split_idxs = np.random.choice([i for i in range(len(data))], num, replace=False)\n","  split_data = data.iloc[split_idxs,:]\n","  # print(split_data)\n","  return split_data\n","\n","def main():\n","  # clf = svm.SVC(gamma=0.5, C=1., kernel='rbf')\n","  clf = svm.SVC(kernel='rbf', random_state=None)\n","  filename = \"wdbc_reg.csv\"\n","  raw_data = pd.read_csv(filename, header=None)                                        #主キー（不要情報）つき\n","  data = raw_data.iloc[:,2:]                                              #目的変数が2重\n","  data.iloc[:,0] = data.iloc[:,0].astype('int')\n","  # print(data)\n","  # train_data = data.iloc[0:528,1:]\n","  # test_data = data.iloc[528:,1:]\n","\n","  # closed_test\n","  closed_test_score = learning_closed_test(data, clf)\n","  # open_test(一回だけ)\n","  open_text_score = learning_open_test(data.iloc[:len(data)//2,:], data.iloc[len(data)//2:,:], clf)\n","  # open_test(交差検定用)\n","  true_score = evaluate_cross_validation(clf, x=data.iloc[:,1:].values, y=data.iloc[:,0].values, K=10)\n","\n","  print(\"closed_test_score:\", closed_test_score)\n","  print(\"open_text_score:\", open_text_score)\n","  print(\"cross_test_score:\", true_score)\n","\n","  data_num_list = [20, 100, 300, len(data)]\n","  sim_time = 100\n","  result = []\n","  for data_num in data_num_list:\n","    ctest_scores, otest_scores, cross_scores = [], [], []\n","    for time in range(sim_time):\n","      copy_data = copy.deepcopy(data)\n","      split_data = get_split_data(copy_data, data_num)\n","      ctest_scores.append(learning_closed_test(split_data, clf))\n","      otest_scores.append(learning_open_test(split_data.iloc[:len(split_data)//2,:], split_data.iloc[len(split_data)//2:,:], clf))\n","      cross_scores.append(evaluate_cross_validation(clf, x=split_data.iloc[:,1:].values, y=split_data.iloc[:,0].values, K=10))\n","    print(\"data_num:\", data_num)\n","    print(\"closed_test_scores:\", np.mean(ctest_scores))\n","    print(\"open_test_scores:\", np.mean(otest_scores))\n","    print(\"cross_test_scores:\", np.mean(cross_scores))\n","    print()\n","    result_one = [data_num, np.mean(ctest_scores), np.mean(otest_scores), np.mean(cross_scores)]\n","    result.append(result_one)\n","  result = pd.DataFrame(result, columns=[\"data_num\", \"closed_test\", \"open_test\", \"cross_test\"])\n","  print(result)\n","\n","\n","\n","  # fig1 = plt.figure()\n","  # ax1 = fig1.add_subplot(111)\n","  # ax12 = ax1.twinx()\n","  # # ax12 = fig1.add_subplot(212)\n","  # fig2 = plt.figure()\n","  # ax2 = fig2.add_subplot(111)\n","\n","  # ax1.set_title(\"accuracy and number of noised attributes\")\n","  # ax1.set_xlabel(\"epsilon\")\n","  # ax1.set_ylabel(\"accuracy\")\n","  # # ax1.plot(epsilon_lst, true_score_lst, color=\"red\", label=\"non-noise\")\n","  # # ax1.plot(epsilon_lst, mean_score_lst, color=\"blue\", label=\"noised\")\n","  # ax1.set_ylim(0.5,1.0)\n","  # ax12.set_ylim(0,34)\n","  # # ax12.plot(epsilon_lst, k_lst, linewidth = 2, label=\"k_num\",linestyle=\"dashed\")\n","  # ax12.set_ylabel(\"k\")\n","  # h1, l1 = ax1.get_legend_handles_labels()\n","  # h2, l2 = ax12.get_legend_handles_labels()\n","  # ax1.legend(h1+h2, l1+l2, loc='lower right')\n","\n","  # # ax2.set_title(\"scores\")\n","  # # ax2.set_xlabel(\"epsilon\")\n","  # # ax2.set_ylabel(\"score\")\n","  # # ax2.plot(epsilon_lst, mean_score_lst, color=\"blue\", label=\"noised\")\n","  # # ax2.plot(epsilon_lst, reduced_mean_score_lst, color=\"green\", label=\"noised_and_reduced\")\n","  # # ax2.legend()\n","  # # plt.show()\n","  # ax2.set_title(\"accuracy with fixed k\")\n","  # ax2.set_xlabel(\"epsilon\")\n","  # ax2.set_ylabel(\"score\")\n","  # # ax2.plot(epsilon_lst, mean_score_lst, color=\"blue\", label=\"noised\")\n","  # # ax2.plot(epsilon_lst, mean15_score_lst, color=\"green\", label=\"noised(k=15)\")\n","  # # ax2.plot(epsilon_lst, mean20_score_lst, color=\"m\", label=\"noised(k=20)\")\n","  # # ax2.plot(epsilon_lst, mean25_score_lst, color=\"black\", label=\"noised(k=25)\")\n","  # ax2.legend()\n","  # plt.show()\n","  # # plt.title(\"scores\")\n","  # # plt.xlabel(\"epsilon\")\n","  # # plt.ylabel(\"score\")\n","  # # plt.plot(epsilon_lst, true_score_lst, color=\"red\", label=\"non-noise\")\n","  # # plt.plot(epsilon_lst, mean_score_lst, color=\"blue\", label=\"noised\")\n","  # # plt.plot(epsilon_lst, reduced_mean_score_lst, color=\"green\", label=\"noised_and_reduced\")\n","  # # plt.legend()\n","\n","main()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q7RvKRVjOTzm"},"outputs":[],"source":["\n","def read_data(filename):\n","  # filename = \"wdbc_reg.csv\"\n","  raw_data = pd.read_csv(filename)\n","  return raw_data\n","\n","def normalize(data):\n","  for column_name, column in data.iteritems():\n","    "]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":378},"executionInfo":{"elapsed":922,"status":"error","timestamp":1658818530119,"user":{"displayName":"川原尚己","userId":"01349954751757802546"},"user_tz":-540},"id":"bDlvroNMSeBQ","outputId":"82d3fffe-b6ef-4df1-ade4-0133827a3f05"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-405ff4196ac1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwdbc_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWDBC_Parser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethods\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#This is the program to drow the PW noose to all attributions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dataset'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}],"source":["import statistics, time\n","import multiprocessing as mp\n","from pathlib import Path\n","from sklearn import svm, metrics\n","from dataset.wdbc_dataset import WDBC_Parser\n","from dataset.methods import *\n","#This is the program to drow the PW noose to all attributions\n","\n","to_mean = lambda l: f\"{round(statistics.mean(l)*100, 2)}%\"\n","\n","def gen_data(_eps=-1, seed=0xE39FE39F, rand_label=False):\n","    dataset = WDBC_Parser(\"./dataset\")\n","\n","    if _eps != -1:\n","        eps = _eps / 34\n","        dataset.PW(eps, seed)\n","        if rand_label:\n","            dataset.random_label(eps, seed)\n","    \n","    return dataset\n","\n","def all_raw():\n","    accs, recalls, precisions = [], [], []\n","    train_set = gen_data()\n","    test_set = gen_data()\n","\n","    for i in range(10):\n","        data_train, label_train = train_set.split(i)\n","        clf = svm.SVC(C=2.1)\n","        clf.fit(data_train, label_train)\n","\n","        data_test, label_test = test_set.split(i, True)\n","        pre = clf.predict(data_test)\n","        ac_score = metrics.accuracy_score(label_test, pre)\n","        recall = metrics.recall_score(label_test, pre)\n","        precision = metrics.precision_score(label_test, pre, zero_division=0)\n","        accs.append(ac_score)\n","        recalls.append(recall)\n","        precisions.append(precision)\n","    \n","    with open(f\"result_wdbc/primitive.csv\", 'a') as ofile:\n","        ofile.write(f\"-1,{to_mean(accs)},{to_mean(recalls)},{to_mean(precisions)}\\n\")\n","\n","def ten_seed(eps=3):\n","    accs, recalls, precisions = [], [], []\n","\n","    seeds = [pow(0xE39FE39F, i, 1 << 32) for i in range(1, 11)]\n","    for seed in seeds:\n","        train_set = gen_data(eps, seed, True)\n","        test_set = gen_data(eps, seed)\n","\n","        for i in range(10):\n","            data_train, label_train = train_set.split(i)\n","            clf = svm.SVC(C=2.1)\n","            clf.fit(data_train, label_train)\n","\n","            data_test, label_test = test_set.split(i, True)\n","            pre = clf.predict(data_test)\n","            ac_score = metrics.accuracy_score(label_test, pre)\n","            recall = metrics.recall_score(label_test, pre)\n","            precision = metrics.precision_score(label_test, pre, zero_division=0)\n","            accs.append(ac_score)\n","            recalls.append(recall)\n","            precisions.append(precision)\n","    \n","    return to_mean(accs), to_mean(recalls), to_mean(precisions)\n","\n","def wait_single(procs):\n","    try:\n","        procs[0].join()\n","    except KeyboardInterrupt:\n","        for p in procs:\n","            p.terminate()\n","        exit()\n","\n","def wait_all(procs):\n","    try:\n","        for p in procs:\n","            p.join()\n","    except KeyboardInterrupt:\n","        for p in procs:\n","            p.terminate()\n","        exit()\n","\n","def one_proc(begin, size):\n","    eps = begin\n","    while eps < begin + size +0.01:\n","    #for eps in range(begin, begin+size*5, 5):\n","        got = ten_seed(eps)\n","        Path(f\"result_wdbc\").mkdir(parents=True, exist_ok=True)\n","        with open(f\"result_wdbc/primitive.csv\", 'a') as ofile:\n","            ofile.write(f\"{eps},{got[0]},{got[1]},{got[2]}\\n\")\n","        eps +=0.2\n","        eps = round(eps,2)\n","\n","def all_batch(max_thread=20):\n","    procs = []\n","    for eps in range(5, 50, 15):\n","        p = mp.Process(target=one_proc, args=(eps, 15))\n","        procs.append(p)\n","        p.start()\n","\n","        if len(procs) == max_thread:\n","            wait_single(procs)\n","            procs = procs[1:]\n","    \n","    wait_all(procs)\n","\n","if __name__ == '__main__':\n","    print(\"Begin:\", time.asctime())\n","    start = time.time()\n","    all_batch()\n","    all_raw()#ノイズを載せない場合の値\n","    print(f\"Time usage: {time.time() - start}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n90PFphwSe9J"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPCQGBQOr0n3PGUgZrNZBzu","collapsed_sections":[],"name":"analyze_with_svm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}
